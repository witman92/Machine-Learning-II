{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad 2 – Machine Learning II"
      ],
      "metadata": {
        "id": "KezS0OOXRfKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALUMNO: WITMAN ZAVALA"
      ],
      "metadata": {
        "id": "J-yg8wvoRg26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profesor: Francisco Pérez Galarce                                                              \n",
        "Formato de entrega. Un notebook en Python con: Código limpio, celdas ordenadas y comentarios. Gráficos y tablas\n",
        "de resultados.\n",
        "Dentro del mismo notebook usando Markdown debe incluir: Descripción del preprocesamiento. Comparación de\n",
        "modelos. Discusión de resultados y conclusiones.\n",
        "La actividad puede ser desarrollada en grupos de máximo 3 personas.  \n",
        "El avance de cada grupo será discutido en la próxima clase, martes 16  de diciembre."
      ],
      "metadata": {
        "id": "7fqrN_e6Rnhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONTEXTO\n",
        "En la actividad anterior se abordó el problema de churn utilizando modelos lineales (regresión logística),\n",
        "analizando el impacto del preprocesamiento, la regularización y las transformaciones polinomiales.\n",
        "En esta actividad se busca extender el análisis hacia modelos no lineales basados en árboles, con énfasis en: -\n",
        "Selección sistemática de hiperparámetros mediante Grid Search Cross-Validation y Random Search\n",
        "Cross Validation. - - -\n",
        "Comparación de desempeño predictivo y costos computacionales de los métodos para seleccionar\n",
        "hiperparámetros.\n",
        "Análisis de varianza de las predicciones en modelos de ensamble (Random Forest).\n",
        "Evaluación mediante métricas de clasificación, curvas ROC y Precision–Recall."
      ],
      "metadata": {
        "id": "-W5qy-lWRqYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OBJETIVOS DE APRENDIZAJE\n",
        "Al finalizar la actividad, la o el estudiante será capaz de:\n",
        "- Ajustar y optimizar un árbol de decisión de clasificación usando validación cruzada.\n",
        "- Interpretar y visualizar el árbol de decisión seleccionado.\n",
        "- Analizar el efecto del número de árboles en la varianza de un Random Forest.\n",
        "- Seleccionar un Random Forest mediante exploración de hiperparámetros.\n",
        "- Comparar modelos no lineales usando métricas robustas para problemas desbalanceados.\n"
      ],
      "metadata": {
        "id": "JXgpeYTuRtry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DESARROLLO"
      ],
      "metadata": {
        "id": "_1D9unHgRwum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FUNCIÓN ÚNICA (la única que se usará en todos los pasos)"
      ],
      "metadata": {
        "id": "G6fTRz6m2j66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIÓN ÚNICA:Evaluación con validación cruzada(F1, ROC-AUC, PR-AUC + curvas)\n",
        "# =============================================================================\n",
        "def evaluar_modelo_cv(modelo, X, y, cv, mostrar_curvas=False):\n",
        "    \"\"\"\n",
        "    Evalúa un modelo con validación cruzada estratificada.\n",
        "    Retorna métricas por fold y un resumen estadístico.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import (\n",
        "        f1_score, roc_auc_score, average_precision_score,\n",
        "        roc_curve, precision_recall_curve\n",
        "    )\n",
        "\n",
        "    resultados = []                     # Guardar métricas fold x fold\n",
        "    curvas = {\"roc\": [], \"pr\": []}     # Guardar curvas ROC y PR\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(cv.split(X, y), start=1):\n",
        "\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx] # Partición\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx] # Partición\n",
        "\n",
        "        modelo.fit(X_train, y_train)                         # Entrenar modelo\n",
        "        y_prob = modelo.predict_proba(X_test)[:, 1]          # Probabilidad\n",
        "        y_pred = (y_prob >= 0.5).astype(int)                 # Predicción bin.\n",
        "\n",
        "        f1 = f1_score(y_test, y_pred)                           # F1-score\n",
        "        roc = roc_auc_score(y_test, y_prob)                     # ROC-AUC\n",
        "        pr  = average_precision_score(y_test, y_prob)           # PR-AUC\n",
        "\n",
        "        resultados.append({\"fold\": fold, \"F1\": f1, \"ROC-AUC\": roc, \"PR-AUC\": pr}) # Guardar\n",
        "\n",
        "        # Guardar curvas\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        rec, prec, _ = precision_recall_curve(y_test, y_prob)\n",
        "        curvas[\"roc\"].append((fpr, tpr))\n",
        "        curvas[\"pr\"].append((rec, prec))\n",
        "\n",
        "    df_res = pd.DataFrame(resultados)                           # Métricas total\n",
        "    resumen = df_res.describe().loc[[\"mean\", \"std\"]]            # Promedio y std\n",
        "\n",
        "    if mostrar_curvas:                                          # Gráficos\n",
        "        plt.figure(figsize=(12,5))\n",
        "        plt.subplot(1,2,1)\n",
        "        for fpr, tpr in curvas[\"roc\"]:\n",
        "            plt.plot(fpr, tpr, alpha=0.4)\n",
        "        plt.title(\"Curvas ROC por fold\")\n",
        "        plt.xlabel(\"FPR\")\n",
        "        plt.ylabel(\"TPR\")\n",
        "\n",
        "        plt.subplot(1,2,2)\n",
        "        for rec, prec in curvas[\"pr\"]:\n",
        "            plt.plot(rec, prec, alpha=0.4)\n",
        "        plt.title(\"Curvas Precision–Recall por fold\")\n",
        "        plt.xlabel(\"Recall\")\n",
        "        plt.ylabel(\"Precision\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return df_res, resumen, curvas\n"
      ],
      "metadata": {
        "id": "dc44qf1w2rcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 0 — Cargar datos y preprocesamiento"
      ],
      "metadata": {
        "id": "4jWZTcCD2uMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                              # Para cálculos numéricos          ←\n",
        "import pandas as pd                             # Para manejar DataFrames           ←\n",
        "import matplotlib.pyplot as plt                 # Para gráficos                     ←\n",
        "import time                                     # Para medir tiempos                ←\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        ")                                               # Métodos de validación y búsqueda ←\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, OneHotEncoder\n",
        ")                                               # Transformaciones                  ←\n",
        "from sklearn.compose import ColumnTransformer   # Preprocesamiento por tipo        ←\n",
        "from sklearn.pipeline import Pipeline           # Pipelines                         ←\n",
        "from sklearn.impute import SimpleImputer        # Imputación                       ←\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree   # Árboles             ←\n",
        "from sklearn.ensemble import RandomForestClassifier          # Random Forest       ←\n",
        "\n",
        "from tabulate import tabulate                  # Para imprimir tablas               ←\n",
        "from pprint import pprint                      # Para mostrar diccionarios          ←\n",
        "\n",
        "\n",
        "# Cargar dataset\n",
        "url = \"https://raw.githubusercontent.com/witman92/Machine-Learning-II/86796bc39783022a0d5f2f47ffde0b4622981deb/Actividad%202/data-churn%20..csv\"\n",
        "df = pd.read_csv(url)                           # Leer datos                        ←\n",
        "\n",
        "print(tabulate(df.head(), headers=\"keys\", tablefmt=\"pretty\"))  # Vista previa     ←\n",
        "\n",
        "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\":1, \"No\":0})               # Mapear objetivo  ←\n",
        "\n",
        "X = df.drop(columns=[\"Churn\"])                 # Variables independientes            ←\n",
        "y = df[\"Churn\"]                                # Variable objetivo                   ←\n",
        "\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()   # Num    ←\n",
        "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist() # Cat   ←\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),   # Imputar medianas                 ←\n",
        "    (\"sc\", StandardScaler())                     # Escalar                          ←\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),  # Imputar moda              ←\n",
        "    (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))     # OneHot                     ←\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [(\"num\", numeric_transformer, numeric_features),\n",
        "     (\"cat\", categorical_transformer, categorical_features)]\n",
        ")                                               # Preprocesamiento completo         ←\n"
      ],
      "metadata": {
        "id": "JxTEdjz323FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 1 — Árbol de decisión con Grid Search y Random Search"
      ],
      "metadata": {
        "id": "g9ongMO-2_kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 1 — Entrenamiento de Árbol de Decisión con Grid Search & Random Search\n",
        "# =============================================================================\n",
        "# Objetivo:\n",
        "# - Ajustar un árbol de decisión\n",
        "# - Optimizar hiperparámetros de forma sistemática\n",
        "# - Comparar Grid Search vs Random Search\n",
        "# - Usar PR-AUC como métrica principal (adecuada para churn desbalanceado)\n",
        "# =============================================================================\n",
        "\n",
        "pipe_dt = Pipeline([\n",
        "    (\"prep\", preprocessor),                          #Preprocesamiento completo\n",
        "    (\"clf\", DecisionTreeClassifier(random_state=42)) #Modelo base:Árbol decisión\n",
        "])\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Definición de grilla de hiperparámetros\n",
        "# Cada parámetro controla complejidad y permite evitar sobreajuste\n",
        "# -----------------------------------------------------------------------------\n",
        "param_dt = {\n",
        "\n",
        "    # Controla la profundidad del árbol\n",
        "    # Valores bajos → modelos simples (alta generalización)\n",
        "    # Valores altos → riesgo de overfitting\n",
        "    \"clf__max_depth\": [None, 3, 5, 8, 12],\n",
        "\n",
        "    # Tamaño mínimo de muestras para dividir nodos\n",
        "    # Valores más altos → ramas más estables\n",
        "    \"clf__min_samples_split\": [2, 10, 25, 50],\n",
        "\n",
        "    # Tamaño mínimo permitido en hojas\n",
        "    # Evita nodos con muy pocos casos (ruido)\n",
        "    \"clf__min_samples_leaf\": [1, 5, 10, 20],\n",
        "\n",
        "    # Criterio de impureza para decidir splits\n",
        "    # gini y entropy → tradicionales en árboles CART\n",
        "    # log_loss → alineado con métricas probabilísticas\n",
        "    \"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"]\n",
        "}\n",
        "\n",
        "# Validación cruzada estratificada → preserva proporción de churn en folds\n",
        "cv5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Usamos PR-AUC como métrica principal\n",
        "# porque prioriza rendimiento en clase Churn (minoritaria)\n",
        "scoring = \"average_precision\"\n",
        "\n",
        "\n",
        "# =============================== GRID SEARCH ===============================\n",
        "\n",
        "t0 = time.perf_counter()                                # Medir tiempo total\n",
        "\n",
        "grid_dt = GridSearchCV(\n",
        "    estimator=pipe_dt,                                  # Pipeline completo\n",
        "    param_grid=param_dt,                                # Grilla exhaustiva\n",
        "    scoring=scoring,                                    # Métrica principal\n",
        "    cv=cv5,                                             # Validación cruzada\n",
        "    n_jobs=-1                                           # Paralelizar\n",
        ")\n",
        "\n",
        "grid_dt.fit(X, y)                                     # Entrenar y evaluar\n",
        "tg = time.perf_counter() - t0                         # Tiempo transcurrido\n",
        "\n",
        "print(\"\\n=== RESULTADO GRID SEARCH (ÁRBOL) ===\")\n",
        "print(grid_dt.best_params_)                           # Hiperparámetros óptimos\n",
        "print(\"Mejor PR-AUC:\", grid_dt.best_score_)\n",
        "print(\"Tiempo GRID:\", tg, \"segundos\")\n",
        "\n",
        "\n",
        "# =============================== RANDOM SEARCH ===============================\n",
        "\n",
        "# Random Search explora el espacio sin probar todas las combinaciones\n",
        "# Es más eficiente cuando la grilla es grande\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "rand_dt = RandomizedSearchCV(\n",
        "    estimator=pipe_dt,\n",
        "    param_distributions=param_dt,              # Mismas variables\n",
        "    n_iter=40,                                 # Solo prueba 40 combinaciones\n",
        "    scoring=scoring,\n",
        "    cv=cv5,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rand_dt.fit(X, y)\n",
        "tr = time.perf_counter() - t0\n",
        "\n",
        "print(\"\\n=== RESULTADO RANDOM SEARCH (ÁRBOL) ===\")\n",
        "print(rand_dt.best_params_)\n",
        "print(\"Mejor PR-AUC:\", rand_dt.best_score_)\n",
        "print(\"Tiempo RANDOM:\", tr, \"segundos\")\n"
      ],
      "metadata": {
        "id": "PkxVLdos-CPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 2 — Evaluar Árbol Óptimo con Validación Cruzada"
      ],
      "metadata": {
        "id": "bp_CLU1n3O-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 2 — Evaluación del Árbol Óptimo seleccionado por Grid Search\n",
        "# =============================================================================\n",
        "\n",
        "best_dt = grid_dt.best_estimator_                  # Selecciona el mejor árbol\n",
        "\n",
        "# Evalúa:\n",
        "# ✓ F1-score\n",
        "# ✓ ROC-AUC\n",
        "# ✓ PR-AUC\n",
        "# ✓ Curvas por fold\n",
        "# ✓ Promedio + desviación estándar\n",
        "df_dt, resumen_dt, curvas_dt = evaluar_modelo_cv(\n",
        "    best_dt, X, y, cv=cv5, mostrar_curvas=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== RESUMEN ÁRBOL DE DECISIÓN ===\")\n",
        "print(resumen_dt)                                    # Métricas promedio y STD\n"
      ],
      "metadata": {
        "id": "LMZHIBB6_9To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 3 — Visualización e Interpretación del Árbol"
      ],
      "metadata": {
        "id": "a4Wx6WWt56z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 3 — Visualización del Árbol de Decisión\n",
        "# =============================================================================\n",
        "# Entrenamos con todos los datos para interpretar reglas\n",
        "# Limitamos profundidad para evitar saturación visual\n",
        "# =============================================================================\n",
        "\n",
        "best_dt.fit(X, y)\n",
        "\n",
        "plt.figure(figsize=(18,10))\n",
        "\n",
        "plot_tree(\n",
        "    best_dt.named_steps[\"clf\"],                              # Extrae árbol desde pipeline\n",
        "    filled=True,                                             # Colores según clase\n",
        "    rounded=True,                                            # Estética\n",
        "    max_depth=3                                              # Solo primeras divisiones\n",
        ")\n",
        "\n",
        "plt.title(\"Árbol de Decisión — Splits más importantes\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V4LFqNsMAMp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 4 — Análisis de VARIANZA en Random Forest"
      ],
      "metadata": {
        "id": "5b8ivcu56OnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 4 — Análisis de Varianza según número de árboles\n",
        "# =============================================================================\n",
        "# Objetivo:\n",
        "# Medir empíricamente cómo aumenta la estabilidad del modelo\n",
        "# cuando incrementamos la cantidad de árboles en el ensamble\n",
        "#\n",
        "# Se evalúan configuraciones:\n",
        "# 2, 4, 8, 16, 32, 64, 128 árboles\n",
        "#\n",
        "# Para cada modelo se calcula:\n",
        "# ✓ Varianza de probabilidades entre folds\n",
        "# ✓ F1 promedio\n",
        "# ✓ ROC-AUC promedio\n",
        "# ✓ PR-AUC promedio\n",
        "# =============================================================================\n",
        "\n",
        "n_trees_list = [2, 4, 8, 16, 32, 64, 128]\n",
        "\n",
        "varianza_pred = []                                  # Varianza entre folds\n",
        "f1_list, roc_list, pr_list = [], [], []             # Métricas promedio\n",
        "\n",
        "for n in n_trees_list:\n",
        "\n",
        "    # Se crea un modelo RF variando únicamente n_estimators\n",
        "    rf_temp = Pipeline([\n",
        "        (\"prep\", preprocessor),\n",
        "        (\"clf\", RandomForestClassifier(\n",
        "            n_estimators=n,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    preds_prob = []                                 # Probabilidades acumuladas\n",
        "\n",
        "    # Evaluación con la misma función central del proyecto\n",
        "    df_tmp, _, _ = evaluar_modelo_cv(rf_temp, X, y, cv=cv5)\n",
        "\n",
        "    # Guardamos métricas promedio del fold\n",
        "    f1_list.append(df_tmp[\"F1\"].mean())\n",
        "    roc_list.append(df_tmp[\"ROC-AUC\"].mean())\n",
        "    pr_list.append(df_tmp[\"PR-AUC\"].mean())\n",
        "\n",
        "    # Calculamos varianza real de predicciones\n",
        "    # recorriendo folds manualmente\n",
        "    for train_idx, test_idx in cv5.split(X, y):\n",
        "\n",
        "        rf_temp.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
        "\n",
        "        probas = rf_temp.predict_proba(X.iloc[test_idx])[:,1] #Probabilidades churn\n",
        "        preds_prob.extend(probas)\n",
        "\n",
        "    varianza_pred.append(np.var(preds_prob))         # Varianza total acumulada\n",
        "\n",
        "\n",
        "# Tabla resumen para análisis\n",
        "df_varianza = pd.DataFrame({\n",
        "    \"n_trees\": n_trees_list,\n",
        "    \"Varianza_Pred\": varianza_pred,\n",
        "    \"F1\": f1_list,\n",
        "    \"ROC-AUC\": roc_list,\n",
        "    \"PR-AUC\": pr_list\n",
        "})\n",
        "\n",
        "print(\"\\n=== VARIANZA vs NÚMERO DE ÁRBOLES ===\")\n",
        "print(df_varianza)\n"
      ],
      "metadata": {
        "id": "xNkyTzzUAc_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gráficos de estabilidad del modelo"
      ],
      "metadata": {
        "id": "HY9AUH7nB6IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "# -------- Varianza de probabilidades ----------\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(n_trees_list, varianza_pred, marker=\"o\")\n",
        "plt.title(\"Varianza de Predicciones vs Número de Árboles\")\n",
        "plt.xlabel(\"Cantidad de árboles\")\n",
        "plt.ylabel(\"Varianza de probabilidad\")\n",
        "\n",
        "# -------- Evolución de métricas ----------\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(n_trees_list, f1_list, marker=\"o\", label=\"F1\")\n",
        "plt.plot(n_trees_list, roc_list, marker=\"o\", label=\"ROC-AUC\")\n",
        "plt.plot(n_trees_list, pr_list, marker=\"o\", label=\"PR-AUC\")\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Métricas vs Número de Árboles\")\n",
        "plt.xlabel(\"Cantidad de árboles\")\n",
        "plt.ylabel(\"Valor de métrica\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M0sz4-sgB8Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PASO 5 — Selección del Mejor Random Forest"
      ],
      "metadata": {
        "id": "1lBJtR3p6jvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================================================================================\n",
        "# PASO 5 — Selección del mejor Random Forest (Random Search)\n",
        "# =================================================================================================================================\n",
        "# Aquí sí exploramos:\n",
        "# ✓ profundidad\n",
        "# ✓ tamaño de hojas\n",
        "# ✓ número de árboles\n",
        "# ✓ cantidad de features por split\n",
        "# ✓ pesos por clase (para desbalance)\n",
        "# =================================================================================================================================\n",
        "pipe_rf = Pipeline([\n",
        "    (\"prep\", preprocessor),                                      # Aplica preprocesamiento (imputación + escalado + OHE)\n",
        "    (\"clf\", RandomForestClassifier(n_jobs=-1, random_state=42))  # Modelo Random Forest (ejecución paralela + reproducible)\n",
        "])\n",
        "\n",
        "param_rf = {\n",
        "    \"clf__n_estimators\": [32, 64, 128, 256],                     # Nº de árboles → más árboles = menor varianza\n",
        "    \"clf__max_depth\": [None, 5, 10, 15],                         # Profundidad máxima → controla complejidad del modelo\n",
        "    \"clf__min_samples_leaf\": [1, 5, 10],                         # Tamaño mínimo de hoja → evita reglas demasiado específicas\n",
        "    \"clf__max_features\": [\"sqrt\", \"log2\", None],                 # Nº de features por split → aumenta diversidad entre árboles\n",
        "    \"clf__class_weight\": [None, \"balanced\"]                      # Balanceo de clases → mejora recall en churn (clase minoritaria)\n",
        "}\n",
        "\n",
        "rand_rf = RandomizedSearchCV(\n",
        "    estimator=pipe_rf,                                           # Pipeline completo (preprocesamiento + RF)\n",
        "    param_distributions=param_rf,                                # Espacio de búsqueda de hiperparámetros\n",
        "    n_iter=40,                                                   # Nº de combinaciones aleatorias probadas\n",
        "    scoring=scoring,                                             # Métrica principal = PR-AUC (adecuada para churn desbalanceado)\n",
        "    cv=cv5,                                                      # Validación cruzada estratificada (preserva proporciones)\n",
        "    n_jobs=-1,                                                   # Usa múltiples núcleos para acelerar el cómputo\n",
        "    random_state=42                                              # Permite reproducir resultados\n",
        ")\n",
        "\n",
        "t0 = time.perf_counter()                                         # Marca tiempo inicio del entrenamiento\n",
        "rand_rf.fit(X, y)                                                # Ejecuta Random Search + Cross Validation\n",
        "trf = time.perf_counter() - t0                                   # Calcula tiempo total de búsqueda\n",
        "\n",
        "print(\"\\n=== MEJOR RANDOM FOREST ===\")\n",
        "print(rand_rf.best_params_)                                      # Hiperparámetros óptimos encontrados\n",
        "print(\"Mejor PR-AUC:\", rand_rf.best_score_)                      # Rendimiento promedio del mejor modelo\n",
        "print(\"Tiempo RF:\", trf)                                         # Tiempo total de entrenamiento y evaluación\n"
      ],
      "metadata": {
        "id": "xthnw1wwJcs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PASO 6 — Comparación Final Árbol vs Random Forest"
      ],
      "metadata": {
        "id": "Z9WcjM_5GOOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASO 6 — Comparación Final de Modelos\n",
        "# =============================================================================\n",
        "\n",
        "best_rf = rand_rf.best_estimator_\n",
        "\n",
        "df_rf, resumen_rf, curvas_rf = evaluar_modelo_cv(\n",
        "    best_rf, X, y, cv=cv5, mostrar_curvas=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== COMPARACIÓN FINAL ===\")\n",
        "\n",
        "print(\"\\nÁRBOL DE DECISIÓN:\")\n",
        "print(resumen_dt)\n",
        "\n",
        "print(\"\\nRANDOM FOREST:\")\n",
        "print(resumen_rf)\n"
      ],
      "metadata": {
        "id": "eGN4G_ZpGP3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 7. Discusión y conclusiones"
      ],
      "metadata": {
        "id": "h065o1VJ-5cX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1. Justificación de los rangos de hiperparámetros**\n",
        "\n",
        "Los rangos definidos para los hiperparámetros del Árbol de Decisión y del Random Forest permiten controlar la **complejidad del modelo**, evitar **overfitting** y mejorar la **interpretabilidad** (en el caso del árbol individual).\n",
        "\n",
        "En el **Árbol de Decisión**, parámetros como `max_depth`, `min_samples_split` y `min_samples_leaf` regulan la profundidad y el tamaño mínimo de las hojas, evitando que el árbol genere reglas demasiado específicas que memoricen el ruido. La inclusión de valores bajos y altos permite explorar modelos simples y complejos.\n",
        "\n",
        "En **Random Forest**, los parámetros seleccionados equilibran:\n",
        "\n",
        "* **Número de árboles (`n_estimators`)** para reducir varianza.\n",
        "* **Profundidad y tamaño de hojas** para limitar el sobreajuste de cada árbol.\n",
        "* **Submuestras de características (`max_features`)** para reducir correlación entre árboles.\n",
        "* **Pesos de clase (`class_weight`)** para mitigar el desbalance entre churn y no churn.\n",
        "\n",
        "En conjunto, los rangos permiten una búsqueda amplia pero controlada, adecuada para impedir sobreajuste y mejorar generalización.\n",
        "\n",
        "\n",
        "### **2. Grid Search vs Random Search**\n",
        "\n",
        "La comparación mostró que:\n",
        "\n",
        "* **Grid Search** tomó cerca de **319 segundos**, explorando exhaustivamente todas las combinaciones posibles.\n",
        "* **Random Search** tomó solo **47 segundos**, probando solo 40 combinaciones aleatorias.\n",
        "\n",
        "Aunque ambos métodos encontraron buenos modelos, **Random Search resultó mucho más eficiente**, llegando a soluciones competitivas en una fracción del tiempo. Esto confirma evidencia teórica: en espacios grandes de hiperparámetros, Random Search tiene casi siempre mejor relación **costo-beneficio** y descubrimiento de regiones óptimas del espacio.\n",
        "\n",
        "### **3. Interpretación de los splits más relevantes del árbol**\n",
        "\n",
        "Los primeros splits del Árbol de Decisión suelen estar asociados a variables clave en problemas de churn tales como:\n",
        "\n",
        "* **Tipo de contrato** (`Contract`)\n",
        "* **Cargos mensuales** (`MonthlyCharges`)\n",
        "* **Antigüedad del cliente** (`tenure`)\n",
        "* **Tipo de servicio de internet** (`InternetService`)\n",
        "\n",
        "Estas variables suelen ofrecer la mayor reducción de impureza, lo que las convierte en las más influyentes para dividir la población entre clientes propensos o no al churn. Esto concuerda con la literatura: clientes con contrato mensual, alta factura y poca antigüedad tienden a presentar más riesgo de abandono.\n",
        "\n",
        "### 4. Análisis de varianza en Random Forest y su relación con bagging\n",
        "\n",
        "Comparando los resultados de la validación cruzada para el Árbol de Decisión (`resumen_dt`) y el Random Forest (`resumen_rf`), observamos lo siguiente:\n",
        "\n",
        "**Árbol de Decisión (`resumen_dt`):**\n",
        "```\n",
        "          fold        F1   ROC-AUC    PR-AUC\n",
        "mean  3.000000  0.558460  0.818074  0.613675\n",
        "std   1.581139  0.017509  0.009084  0.031792\n",
        "```\n",
        "\n",
        "**Random Forest (`resumen_rf`):**\n",
        "```\n",
        "          fold        F1   ROC-AUC    PR-AUC\n",
        "mean  3.000000  0.624881  0.841510  0.655318\n",
        "std   1.581139  0.015107  0.012385  0.029837\n",
        "```\n",
        "\n",
        "**Relación con Bagging y Reducción de Varianza:**\n",
        "\n",
        "*   **Mejora en Métricas:** El Random Forest supera consistentemente al Árbol de Decisión en todas las métricas de rendimiento promedio (`mean`). Por ejemplo, el F1-score promedio del RF es `0.624881` vs. `0.558460` del DT; el ROC-AUC es `0.841510` vs. `0.818074`; y el PR-AUC es `0.655318` vs. `0.613675`.\n",
        "\n",
        "*   **Reducción de Varianza:** Para el F1-score, la desviación estándar (`std`) del Árbol de Decisión es `0.017509`, mientras que la del Random Forest es `0.015107`. Para el PR-AUC, la `std` del Árbol de Decisión es `0.031792`, y la del Random Forest es `0.029837`. Aunque la reducción en la desviación estándar para estas métricas no es drástica en este caso particular, sí observamos una ligera disminución, lo que indica una mayor estabilidad del modelo Random Forest entre los diferentes folds de validación cruzada.\n",
        "\n",
        "Esta reducción de varianza es una de las principales ventajas del Random Forest y se explica por el principio de **bagging (bootstrap aggregating)**. El bagging funciona de la siguiente manera:\n",
        "    1.  Se generan múltiples submuestras (con reemplazo) del conjunto de datos de entrenamiento original (bootstrap).\n",
        "    2.  Se entrena un árbol de decisión en cada una de estas submuestras. Los árboles individuales suelen ser de alta varianza (propensos a overfitting).\n",
        "    3.  Para hacer una predicción, el Random Forest combina las predicciones de todos los árboles individuales (por voto mayoritario para clasificación o promediando para regresión).\n",
        "\n",
        "El aspecto clave que diferencia al Random Forest de un simple bagging es la selección aleatoria de características (`max_features`) en cada split de cada árbol. Esto asegura que los árboles individuales sean lo más **decorrelacionados** posible. Cuando se promedian las predicciones de muchos modelos de alta varianza pero decorrelacionados, la varianza del modelo combinado se reduce significativamente, resultando en un modelo más robusto y con mejor capacidad de generalización. La teoría detrás de esto es que el error de un ensemble es menor si los errores de sus componentes son independientes o débilmente correlacionados. Al reducir la varianza, el Random Forest es menos sensible a las pequeñas fluctuaciones en los datos de entrenamiento y generaliza mejor a datos no vistos, como se evidencia en las métricas de rendimiento mejoradas y la ligeramente menor desviación estándar en los resultados de la validación cruzada.\n",
        "\n",
        "### 5. Métrica prioritaria para retención (desde perspectiva de negocio) y por qué?\n",
        "\n",
        "Desde una perspectiva de negocio para campañas de retención de clientes, la métrica que priorizaría es el **PR-AUC (Area Under the Precision-Recall Curve)**, también conocido como Average Precision Score.\n",
        "\n",
        "**Justificación:**\n",
        "\n",
        "1.  **Enfoque en la Clase Positiva (Churners):** En el contexto de retención, la clase positiva son los clientes que van a 'churnear' (abandonar). Las campañas de retención están dirigidas específicamente a estos clientes para evitar su partida. El PR-AUC se enfoca directamente en el rendimiento del modelo para la clase positiva, a diferencia del ROC-AUC que considera ambas clases por igual.\n",
        "2.  **Manejo de Clases Desbalanceadas:** Los problemas de predicción de churn suelen tener un desbalance de clases significativo (muchos clientes no churnean, pocos sí). En estos escenarios, el ROC-AUC puede ser optimista y engañoso, ya que un modelo que clasifica a casi todos como la clase mayoritaria (no churn) aún puede tener un ROC-AUC decente. El PR-AUC es mucho más sensible a los errores en la clase minoritaria y proporciona una evaluación más honesta del rendimiento del modelo cuando la clase positiva es rara e importante.\n",
        "3.  **Equilibrio entre Precisión y Recall:** Para una campaña de retención, tanto la precisión como el recall son vitales:\n",
        "    *   **Recall (Sensibilidad):** Queremos identificar a **la mayor cantidad posible** de clientes que realmente van a churnear para poder contactarlos. Un bajo recall significa que muchos churners potenciales no serán identificados y se perderán.\n",
        "    *   **Precisión:** Queremos que los clientes que el modelo predice como churners **realmente lo sean**. Una baja precisión significa que contactaremos a muchos clientes que no tenían intención de irse, lo que puede resultar en costos innecesarios (ofertas, recursos de personal) e incluso molestar a clientes leales.\n",
        "    El PR-AUC integra el rendimiento de precisión y recall en todos los umbrales posibles, proporcionando una visión completa de esta compensación, lo cual es exactamente lo que necesitamos para una estrategia de retención efectiva.\n",
        "\n",
        "**En resumen:** Para una empresa, el costo de perder un cliente (falso negativo: un churner que el modelo no detectó) es alto, y el costo de invertir en retención para un cliente que no iba a irse (falso positivo) también lo es. El PR-AUC nos ayuda a encontrar el mejor equilibrio entre identificar a la mayoría de los churners y asegurarnos de que nuestras intervenciones sean lo más dirigidas y eficientes posible.\n",
        "\n"
      ],
      "metadata": {
        "id": "WYKrVBbRO0-K"
      }
    }
  ]
}